{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential,layers,Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Movie genere classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is just crap. Even though the direc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Another detailed work on the subject by Dr Dwi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE CAT O'NINE TAILS (Il Gatto a Nove Code) &lt;b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Like with any movie genre, there are good gang...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I watched it with my mom and we were like...&lt;b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  This movie is just crap. Even though the direc...          0\n",
       "1  Another detailed work on the subject by Dr Dwi...          1\n",
       "2  THE CAT O'NINE TAILS (Il Gatto a Nove Code) <b...          0\n",
       "3  Like with any movie genre, there are good gang...          0\n",
       "4  I watched it with my mom and we were like...<b...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49969 entries, 0 to 49968\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     49969 non-null  object\n",
      " 1   sentiment  49969 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 780.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(418)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49551 entries, 0 to 49968\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     49551 non-null  object\n",
      " 1   sentiment  49551 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie is just crap. Even though the directors claim to be part of that oi-culture, it's still a very, very bad directorial debut. The topic itself is very interesting and I accept the bad acting due to the fact, that they are all amateurs and never acted before, but the worst thing about this film are the dialogs and very unexperienced and naive directing. There's no timing at all in that movie. I felt like the directors were so exited to do that movie (it's their first feature), that they actually never really asked themselves, what story they wanna tell. I met Ben (one of the directors) on several occasions and he's a nice and thoughtful guy, but that doesn't make him a director. I think, that \"American History X\" is full of clichÃ©s, but somehow manages to transport a story. \"Oi!Warning\" is full of clichÃ©s, doesn't tell anything new or provocative and (-that's the sad thing about this movie) it's far from any Oi!-Reality.<br /><br />If you wanna see weird but great German films, watch the movies of Michael Haneke, Christoph Schlingensief, Oskar Roehler, Hans Weingartner or Oliver Hirschbiegel:<br /><br />Benny's Video Funny Games Die UnberÃ¼hrbare Mein Letzter Film Das Experiment Das Weisse Rauschen MuxmÃ¤uschenstill ...<br /><br />*** out of ten, because of the topic and the photography\n",
      "Another detailed work on the subject by Dr Dwivedi takes us back in time to pre-partioned Panjab. Dr Dwivedi chose a difficult subject for his movie debut. He has worked on all meticulous details to bring the story to life. The treatment of the subject is very delicate.<br /><br />Even though we have not been to the region during that time, the sets and costumes look real. Unlike most movies made on partition, this one focuses not on the gory details of violence to attract audience, but on its after-effects. The characters come to life. Priyanshu Chatterjee has given an impressive performance. Manoj Bajpai has acted his heart out showing the plight of a guilt-ridden man. The rest of the cast has done a good job too.\n",
      "THE CAT O'NINE TAILS (Il Gatto a Nove Code) <br /><br />Aspect ratio: 2.35:1 (Cromoscope)<br /><br />Sound format: Mono<br /><br />(35mm and 70mm release prints)<br /><br />A blind ex-journalist (Karl Malden) overhears a blackmail plot outside a genetics research laboratory and later teams up with a fellow reporter (James Franciscus) to investigate a series of murders at the lab, unwittingly placing their own loved ones at the mercy of a psychopathic killer.<br /><br />Rushed into production following the unexpected worldwide success of his directorial debut THE BIRD WITH THE CRYSTAL PLUMAGE (1969), Dario Argento conceived THE CAT O'NINE TAILS as a giallo-thriller in much the same vein as its forerunner, toplining celebrated Hollywood actor Karl Malden - fresh from his appearance in PATTON (1969) - and rising star Franciscus (THE VALLEY OF GWANGI). Sadly, the resulting film - which the ads claimed was 'nine times more suspenseful' than \"Bird\" - is a disappointing follow-up, impeccably photographed and stylishly executed, but too plodding and aimless for general consumption.<br /><br />Malden and Franciscus are eminently watchable in sympathetic roles, and cinematographer Enrico Menczer (THE DEAD ARE ALIVE) uses the wide Cromoscope frame to convey the hi-tech world in which Argento's dark-hearted scenario unfolds, but the subplot involving Euro starlet Catherine Spaak (THE LIBERTINE) as Franciscus' romantic interest amounts to little more than unnecessary padding. Highlights include an unforgettable encounter with the black-gloved assassin in a crowded railway station (edited with sleek assurance by cult movie stalwart Franco Fraticelli), and a nocturnal episode in which Malden and Franciscus seek an important clue inside a mouldering tomb and fall prey to the killer's devious machinations. But despite these flashes of brilliance, the film rambles aimlessly from one scene to the next, simmering gently without ever really coming to the boil. It's no surprise that \"Cat\" failed to emulate the runaway success of \"Bird\" when released in 1971.<br /><br />(English version)\n",
      "Like with any movie genre, there are good gangster movies and there are bad gangster movies. If you asked me to name a good gangster movie, I'd have dozens to choose from. If you asked me to name a bad gangster movie, probably the first one to pop up in my mind is one that still has me in a sort of depression of disappointment about a week since I saw the film for the first and I promise you, the last time. That film is \"The General\", unrelated to the 1926 silent film of the same name. This is a very dry, very slow gangster epic that raises questions not about the story (it's more than easy to follow) but about why the filmmakers chose to make this rather flimsy endeavor.<br /><br />Like \"Goodfellas\" (1990) and \"American Gangster\" (2007)Â—two superior mob moviesÂ—\"The General\" is based on real people and true events. The film revolves around an Irish criminal named Martin Cahill (Brendan Gleeson) who started his long chain of crimes stealing food as a teenager and then moving up to robbing museums and houses as an adult. Meanwhile, the police led by an inspector named Kenny (Jon Voight) try desperately and vigorously to prove just one of his crimes and convict (or kill) him.<br /><br />Perhaps because it's a film in the same category as the marvelous \"Goodfellas\" (1990) and the first two \"Godfather\" films, I was expecting too much from \"The General.\" But that may be going too easy on it. This would have been a bad film had I not seen the aforementioned masterpieces before being swamped by boredom in this oater and its far-too-stretched running time of screaming bad scenes. Let's start knocking the film by just looking at the style in which it is presented. For some reason, director John Boorman and cinematographer Seamus Deasy selected to film this movie in black-and-white while its style and presentation are clearly the elements that belong to a full-fledged color film. Now I have nothing against b/w pictures, not even ones made in modern-day times. \"Schindler's List\" (1993) was more than ninety percent filmed in black-and-white and it's a masterpiece. \"The General\", made just five years after \"Schindler's List\" is not. The cinematography is also far too blown out with high lighting keys that seem very distracting and give the movie a very video-game-like quality that I found simply annoying. The filmmakers were obviously going for a realist's documentary-like style, like \"Schindler's List\" did, but they fail by making it seem too much like a documentary and at the same time, too much like a classic-style motion picture. Performances in the film range from passable to poor. Brendan Gleeson and Jon Voight gave decent enthusiasm for their roles, but it seemed to me at times that even they were getting kind of run down by the awful screenplay from which they were quoting. The sound design is also very primitive, probably in an attempt to give it a 40s crime-noir appeal, but that also fails because again, it's made too much like a contemporary picture and seems vastly out of place.<br /><br />But the worst thing that occurs is that there's not oneÂ—not oneÂ—character in the film that I felt any emotions or opinions for. In fact, for every moment of every scene, the only thought going through my head was \"okayÂ…so what?\" Moments that in a better film might come across as shocking or appalling are just dull and time-consuming here. I did not sympathize or hate the Brendan Gleeson character because the way the Cahill character is written is simply flat and dull. Gleeson just plays the common criminal and does not strike out with the impact the real Martin Cahill obviously did. If a character is killed off (as they always are in gangster films), we feel nothing. No remorse, no relief, no surprise, nothing. We just say \"so what?\" And that's all I did during the entire running time of this very flimsy, very poorly-made crime film.\n",
      "I watched it with my mom and we were like...<br /><br />What the hell? We didn't get it at all. I may have this wrong, but a chair had something to do with the death of this woman's father. That movie was terrible! This is not a movie for those who love a good suspense movie. Bad suspense movie! *shakes cane at movie* I'm never seeing it again. And I'm a big fan of lifetime movies, too! They kinda need to quit trying to make movies outta books. It's driving me crazy!!!<br /><br />And Whit was butt-ugly and yet, she loves him more than Hugh, who was a TINY bit nicer-looking.<br /><br />My rating: 1/10\n",
      "This movie is probably one of 3 worst movies made in history. I rented this by chance, without reading reviews, and wow, do I regret it. Really has no plot, doesn't really follow the vampire genre. Just plain god awful. Watching this movie will taint your enthusiasm for vampire movies. I felt like the writer/director/producer went on this drug binge and had hallucinations and tried to recreate it on film. Whole time I wanted the movie to end.. but the ending was even more whacked. <br /><br />If this review can save just one person from watching this crap, I felt my time spent on registration and writing this review was well worth it.\n",
      "this movie is quite bad, aggressive, not played well, not directed well, seems low budget, low quality,emotionaly weak and disconnected. after watching earlier comments, went to see it, but if u try to compare it with apocalypse now, PLATOON, or any others, u'r really off the tracks. this movie looks like a 60's old and purely made film with cast of grown neanderthals, not to mention (or actually do), not paying attention to details like changing rounds, low budget fireworks and all sorts of poorly filmed characteristic. is watchable though, if u'd like to see it as an early development of the movies document.. not to go back!!<br /><br />p.s - afterall, the guys are quite alright.\n",
      "And a perfect film to watch during the holiday season as the winter/Xmas atmosphere that Burton creates for Gotham City is way cool. It's weird that Warner decided to release this as a summer film. It doesn't fit.<br /><br />But what's even weirder, when you consider the content of this film, is that it was aimed at families. An upper-class family throws their mutant baby down the sewer, a socio phobic billionaire dresses up in leather as a flying rodent, a lonely secretary dresses up in leather as a feline and a freak runs for political office. And S&M and bondage are presented in a very perverted way. But Burton got away with it. His visual style in this film is at it's best.<br /><br />This and Batman: Dead End are the only true live-action incarnations of the comic-book character. True, the animated series was the closest to the source material, but compared with Batman Forever and the un-nameable one after that, Batman Returns is the best of the four.<br /><br />Darker and more violent than the first movie, the sense of Gothic pathos reaches a new high. I was quite keen on Michael Keaton as Bruce Wayne (don't even get me started on George Clooney!), he displayed the right balance of weirdo loner and cool crime fighter. Michelle Pfieffer is great as Catwoman (much sexier and more 'realisticly' cat-like), she wears that leather outfit better than Halle Berry. And Danny DeVito was so convincing as the Penguin that his scenes became disturbing to watch. And Christopher Walken is brilliant as the spooky Max Shreck (if you think you recognise Chip Shrek it's none other than a very young Leatherface/Butterfinger).<br /><br />Danny Elfman's score is also even better than it was first time round. His powerful and engaging themes are way better than the dross that followed in the later 2 Schumacher movies. This movie is the Batman phenomenon at its Zenith. Forget the following sequels and stick to the animated series after this. Let's hope that Christopher Nolan and Christian Bale can bring some integrity back to the live action Batman with their movie next year.<br /><br />This DVD was one of the first ever DVDs released by Warner (almost 7 years ago!!!) and as a result there are NO features and the case is a snapper. Pick it up cheap like I did and hope for an SE in the future.\n",
      "I like Noel Coward, the wit. I like Noel Coward, the play write. I like Noel Coward, the composer and singer, but I loathe Noel Coward the actor.<br /><br />To me this is a man who should have stayed firmly behind the scenes, writing his plays and composing his music and making his profound and hilarious observations. He should never have been allowed in front of a camera.<br /><br />Make no mistake, he is one of the top outstanding talents of the 20th century but the man just couldn't act, and his voice...with it's rolling R's and it's overly round tonal quality...well it could quite easily grate cheese in my opinion.<br /><br />This is one of my least favourite offerings from Coward, as he unconvincingly portrays a psychiatrist embarking on an affair with a much younger woman, made worse by the fact that the much younger woman is an old school friend of his much younger wife.<br /><br />Celia Johnson is as much a joy to watch as ever as Cowards wronged wife. It is her performance that saves this film from abject dullness. I suppose her own little fling in Coward's Brief Encounter four years previously qualified her for this role as she must have raised a few eyebrows playing a such a promiscuous woman and this gave her the chance to win back a few fans and gain some lost sympathy.<br /><br />She was such a wonderful actress and you can see why Noel Coward used her so much in many of his productions.<br /><br />However the rest of the film is drab, badly acted, predictable and on the whole boring to almost arse-clenching level.<br /><br />If its Noel Coward you want then take the time to watch In Which We Serve, Blythe Spirit or This Happy Breed instead. Three Noel Coward treasures. With lovely films like these I suppose we can forgive him for this turkey.<br /><br />I have given this four stars purely for the addition of Miss Johnson, but on the whole I'd avoid this one like the plague.\n",
      "\"The Days\" is a typical family drama with a little catch - you must relate to the character's emotions in every way possible in order for you to truly appreciate the show.<br /><br />[Possible Spoilers For Those Who Are Unfamiliar With the Show]<br /><br />The story, obviously, for all the people who has watched the show, is the world of Cooper Day, the middle child of the family. He records his days with his family and hopes to become a rich and famous writer one day because of his observations. His family includes a mother, a father, a perfect sister, and a genius-little-brother. The first episode, which is going to sound a bit stupid since John Scott Shepard has created this situation - both the sister and mother gets pregnant. That's the first situation the writer hits. Then the father quits his job at the law firm. The youngest son gets a panic attack. The middle child gets in a fight with the sister's boyfriend. This is all in a day's work.<br /><br />[/Spoilers]<br /><br />I admire this show. I don't know. It's a bit crappy but I like it. First I thought the camera-work was a ripoff but then I got used it and started to like it. I liked the quiet conversations under a dark light. I liked the intimate feeling of the show. I liked the low-budget style. I liked the acting. I admire the story. Then I find myself wanting a second season of The Days. I slowly became a fan of it as the 6-episode airing on ABC came to an end. It's a really good show and it's nothing like The OC. The two have nothing in common. So I hope fans will stop comparing them.<br /><br />And if you can relate to either Abby, Jack, Natalie, Cooper or even Nate, you'll like this show. A lot.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(df['review'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['review']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer.texts_to_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pad_sequences(x, maxlen=400,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  11,   17,    6, ...,    0,    0,    0],\n",
       "       [ 157, 3618,  158, ...,    0,    0,    0],\n",
       "       [   1, 1257,    3, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  31,    1,   55, ...,    0,    0,    0],\n",
       "       [  69,   43,   22, ...,    0,    0,    0],\n",
       "       [ 117,   11,   17, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  32,   87,   19, ...,    0,    0,    0],\n",
       "       [  11, 1380,   61, ...,    0,    0,    0],\n",
       "       [  11,    6,    1, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  10,  209,   11, ...,    0,    0,    0],\n",
       "       [  31,    1,  892, ...,    0,    0,    0],\n",
       "       [   4,   85,    2, ...,   41,  147,   11]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 128,input_shape=(xtrain.shape[1],)))\n",
    "model.add(layers.GRU(62))\n",
    "model.add(layers.Dense(128,activation='elu'))\n",
    "model.add(layers.Dense(64,activation='elu'))\n",
    "model.add(layers.Dense(32,activation='elu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m991/991\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 74ms/step - accuracy: 0.5026 - loss: 0.6937 - val_accuracy: 0.5144 - val_loss: 0.6884\n",
      "Epoch 2/10\n",
      "\u001b[1m991/991\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 74ms/step - accuracy: 0.5240 - loss: 0.6813 - val_accuracy: 0.5235 - val_loss: 0.6816\n",
      "Epoch 3/10\n",
      "\u001b[1m991/991\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 75ms/step - accuracy: 0.6939 - loss: 0.5250 - val_accuracy: 0.8949 - val_loss: 0.2634\n",
      "Epoch 4/10\n",
      "\u001b[1m991/991\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 74ms/step - accuracy: 0.9262 - loss: 0.1994 - val_accuracy: 0.9012 - val_loss: 0.2470\n",
      "Epoch 5/10\n",
      "\u001b[1m991/991\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 75ms/step - accuracy: 0.9554 - loss: 0.1306 - val_accuracy: 0.8976 - val_loss: 0.2933\n",
      "Epoch 6/10\n",
      "\u001b[1m640/991\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 69ms/step - accuracy: 0.9762 - loss: 0.0760"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\muham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain,epochs=10,validation_split=0.2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m640,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)             │        \u001b[38;5;34m35,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,082,821</span> (7.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,082,821\u001b[0m (7.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">694,273</span> (2.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m694,273\u001b[0m (2.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,388,548</span> (5.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,388,548\u001b[0m (5.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1239/1239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - accuracy: 0.9813 - loss: 0.0627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11602896451950073, 0.9650605320930481]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  39,  289,   11, ...,    0,    0,    0],\n",
       "       [  11,  248, 4489, ...,    0,    0,    0],\n",
       "       [  21,   57, 1928, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  15,   83,   37, ...,    0,    0,    0],\n",
       "       [  82,    1, 1143, ...,   22, 2723,  142],\n",
       "       [   6,   54, 1472, ..., 1188,    5,  362]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 111ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [1 if pred>.5 else 0 for pred in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9911,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915346584602967"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(ytest,pred),annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      4917\n",
      "           1       0.89      0.90      0.89      4994\n",
      "\n",
      "    accuracy                           0.89      9911\n",
      "   macro avg       0.89      0.89      0.89      9911\n",
      "weighted avg       0.89      0.89      0.89      9911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
